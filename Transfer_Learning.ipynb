{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-jhonattan/Transfer_Learning/blob/main/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cTnqqD1uupuJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnHEO8YxvRC_"
      },
      "outputs": [],
      "source": [
        "# 1. Carregar dataset\n",
        "(ds_train_raw, ds_val_raw, ds_test_raw), ds_info = tfds.load(\n",
        "    'oxford_flowers102',\n",
        "    split=['train', 'validation', 'test'],\n",
        "    with_info=True,\n",
        "    as_supervised=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UOSV6WdvZj_",
        "outputId": "cfe80720-7351-4607-ce6d-af2c8a375636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de labels: 1020\n",
            "Primeiros 10 labels: [72 84 70 51 48 83 42 58 40 35]\n",
            "Contagem por classe: {np.int64(0): np.int64(10), np.int64(1): np.int64(10), np.int64(2): np.int64(10), np.int64(3): np.int64(10), np.int64(4): np.int64(10), np.int64(5): np.int64(10), np.int64(6): np.int64(10), np.int64(7): np.int64(10), np.int64(8): np.int64(10), np.int64(9): np.int64(10), np.int64(10): np.int64(10), np.int64(11): np.int64(10), np.int64(12): np.int64(10), np.int64(13): np.int64(10), np.int64(14): np.int64(10), np.int64(15): np.int64(10), np.int64(16): np.int64(10), np.int64(17): np.int64(10), np.int64(18): np.int64(10), np.int64(19): np.int64(10), np.int64(20): np.int64(10), np.int64(21): np.int64(10), np.int64(22): np.int64(10), np.int64(23): np.int64(10), np.int64(24): np.int64(10), np.int64(25): np.int64(10), np.int64(26): np.int64(10), np.int64(27): np.int64(10), np.int64(28): np.int64(10), np.int64(29): np.int64(10), np.int64(30): np.int64(10), np.int64(31): np.int64(10), np.int64(32): np.int64(10), np.int64(33): np.int64(10), np.int64(34): np.int64(10), np.int64(35): np.int64(10), np.int64(36): np.int64(10), np.int64(37): np.int64(10), np.int64(38): np.int64(10), np.int64(39): np.int64(10), np.int64(40): np.int64(10), np.int64(41): np.int64(10), np.int64(42): np.int64(10), np.int64(43): np.int64(10), np.int64(44): np.int64(10), np.int64(45): np.int64(10), np.int64(46): np.int64(10), np.int64(47): np.int64(10), np.int64(48): np.int64(10), np.int64(49): np.int64(10), np.int64(50): np.int64(10), np.int64(51): np.int64(10), np.int64(52): np.int64(10), np.int64(53): np.int64(10), np.int64(54): np.int64(10), np.int64(55): np.int64(10), np.int64(56): np.int64(10), np.int64(57): np.int64(10), np.int64(58): np.int64(10), np.int64(59): np.int64(10), np.int64(60): np.int64(10), np.int64(61): np.int64(10), np.int64(62): np.int64(10), np.int64(63): np.int64(10), np.int64(64): np.int64(10), np.int64(65): np.int64(10), np.int64(66): np.int64(10), np.int64(67): np.int64(10), np.int64(68): np.int64(10), np.int64(69): np.int64(10), np.int64(70): np.int64(10), np.int64(71): np.int64(10), np.int64(72): np.int64(10), np.int64(73): np.int64(10), np.int64(74): np.int64(10), np.int64(75): np.int64(10), np.int64(76): np.int64(10), np.int64(77): np.int64(10), np.int64(78): np.int64(10), np.int64(79): np.int64(10), np.int64(80): np.int64(10), np.int64(81): np.int64(10), np.int64(82): np.int64(10), np.int64(83): np.int64(10), np.int64(84): np.int64(10), np.int64(85): np.int64(10), np.int64(86): np.int64(10), np.int64(87): np.int64(10), np.int64(88): np.int64(10), np.int64(89): np.int64(10), np.int64(90): np.int64(10), np.int64(91): np.int64(10), np.int64(92): np.int64(10), np.int64(93): np.int64(10), np.int64(94): np.int64(10), np.int64(95): np.int64(10), np.int64(96): np.int64(10), np.int64(97): np.int64(10), np.int64(98): np.int64(10), np.int64(99): np.int64(10), np.int64(100): np.int64(10), np.int64(101): np.int64(10)}\n"
          ]
        }
      ],
      "source": [
        "# 2. Extração de labels - Método 100% funcional\n",
        "def extract_labels(dataset):\n",
        "    labels = []\n",
        "    for _, label in tfds.as_numpy(dataset):  # Itera sobre o dataset convertido para numpy\n",
        "        labels.append(int(label))  # Converte explicitamente para inteiro\n",
        "    return np.array(labels)\n",
        "\n",
        "train_labels = extract_labels(ds_train_raw)\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Verificação\n",
        "print(\"Número de labels:\", len(train_labels))\n",
        "print(\"Primeiros 10 labels:\", train_labels[:10])\n",
        "print(\"Contagem por classe:\", {i: np.sum(train_labels==i) for i in np.unique(train_labels)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGUzR8uuwAPc"
      },
      "outputs": [],
      "source": [
        "# 3. Pré-processamento para EfficientNet\n",
        "def preprocess(image, label, img_size=224):\n",
        "    image = tf.image.resize(image, [img_size, img_size])\n",
        "    image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5aPrXFOwXeg"
      },
      "outputs": [],
      "source": [
        "# 4. Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.2)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6es3Eb7weoh"
      },
      "outputs": [],
      "source": [
        "# 5. Pipeline de dados\n",
        "def prepare_dataset(ds, batch_size=32, augment=False):\n",
        "    ds = ds.map(lambda x, y: preprocess(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if augment:\n",
        "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_train = prepare_dataset(ds_train_raw, augment=True)\n",
        "ds_val = prepare_dataset(ds_val_raw)\n",
        "ds_test = prepare_dataset(ds_test_raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GS_nulYxG-Y"
      },
      "outputs": [],
      "source": [
        "# 6. Modelo EfficientNetB0 CORRIGIDO\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9NYUz0RxsUo"
      },
      "outputs": [],
      "source": [
        "# 7. Adicionando Dropout manualmente (substituto para drop_connect)\n",
        "x = base_model.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.4)(x)  # Dropout adicional\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)  # Dropout final\n",
        "outputs = layers.Dense(102, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs=base_model.input, outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlsyyLxfx2AC"
      },
      "outputs": [],
      "source": [
        "# 8. Compilação\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyDG3yo4zeUE",
        "outputId": "31c688c2-21d2-4e2f-96f1-837e25a9139a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 12s/step - accuracy: 0.0820 - loss: 5.2450 - val_accuracy: 0.1225 - val_loss: 4.1116 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 12s/step - accuracy: 0.5025 - loss: 2.0602 - val_accuracy: 0.2971 - val_loss: 3.0777 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 11s/step - accuracy: 0.7036 - loss: 1.1172 - val_accuracy: 0.5647 - val_loss: 1.8188 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 11s/step - accuracy: 0.8368 - loss: 0.5984 - val_accuracy: 0.6971 - val_loss: 1.2854 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 11s/step - accuracy: 0.9134 - loss: 0.3234 - val_accuracy: 0.7696 - val_loss: 0.9254 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 11s/step - accuracy: 0.9369 - loss: 0.2265 - val_accuracy: 0.7951 - val_loss: 0.8212 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 11s/step - accuracy: 0.9534 - loss: 0.1564 - val_accuracy: 0.8206 - val_loss: 0.6607 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 12s/step - accuracy: 0.9709 - loss: 0.1114 - val_accuracy: 0.8167 - val_loss: 0.6741 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 12s/step - accuracy: 0.9850 - loss: 0.0839 - val_accuracy: 0.8127 - val_loss: 0.7097 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 11s/step - accuracy: 0.9661 - loss: 0.1222 - val_accuracy: 0.8049 - val_loss: 0.7607 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 11s/step - accuracy: 0.9852 - loss: 0.0639 - val_accuracy: 0.8314 - val_loss: 0.6933 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 12s/step - accuracy: 0.9831 - loss: 0.0678 - val_accuracy: 0.8412 - val_loss: 0.6402 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 11s/step - accuracy: 0.9937 - loss: 0.0403 - val_accuracy: 0.8441 - val_loss: 0.6213 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 12s/step - accuracy: 0.9856 - loss: 0.0592 - val_accuracy: 0.8490 - val_loss: 0.6149 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 11s/step - accuracy: 0.9928 - loss: 0.0455 - val_accuracy: 0.8510 - val_loss: 0.6032 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 12s/step - accuracy: 0.9874 - loss: 0.0612 - val_accuracy: 0.8529 - val_loss: 0.5898 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 12s/step - accuracy: 0.9980 - loss: 0.0226 - val_accuracy: 0.8608 - val_loss: 0.5817 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 12s/step - accuracy: 0.9962 - loss: 0.0315 - val_accuracy: 0.8647 - val_loss: 0.5778 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 11s/step - accuracy: 0.9867 - loss: 0.0380 - val_accuracy: 0.8637 - val_loss: 0.5742 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 11s/step - accuracy: 0.9966 - loss: 0.0263 - val_accuracy: 0.8569 - val_loss: 0.5732 - learning_rate: 1.0000e-04\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 2s/step - accuracy: 0.8381 - loss: 0.6660\n",
            "\n",
            "Acurácia no teste: 83.74%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 9. Treinamento\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_val,\n",
        "    epochs=20,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[\n",
        "        callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "        callbacks.ReduceLROnPlateau(patience=3)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 10. Avaliação\n",
        "test_loss, test_acc = model.evaluate(ds_test)\n",
        "print(f'\\nAcurácia no teste: {test_acc:.2%}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "721Q1Uq9akMz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKoV1SHCXlZbEyISc4/KYf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}